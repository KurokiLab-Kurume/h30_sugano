{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "from builtins import range\n",
    "\n",
    "#import pyfftw   # See https://github.com/pyFFTW/pyFFTW/issues/40\n",
    "import numpy as np\n",
    "import functools\n",
    "import operator\n",
    "import matplotlib.pyplot as mplot\n",
    "mplot.rcParams[\"axes.grid\"] = False\n",
    "import math\n",
    "import pprint\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from scipy.linalg import toeplitz\n",
    "from sporco.dictlrn import cbpdndl\n",
    "from sporco.admm import cbpdn\n",
    "from sporco import util\n",
    "from sporco import plot\n",
    "from sporco import cnvrep\n",
    "import sporco.linalg as sl\n",
    "import sporco.metric as sm\n",
    "from sporco.admm import ccmod\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr\n",
    "plot.config_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2norm(A):\n",
    "    l2norm = np.sum( abs(A)*abs(A) )\n",
    "    return l2norm\n",
    "\n",
    "def l0norm(A, threshold):\n",
    "    return np.where(abs(A) < threshold, 0, 1).sum()\n",
    "\n",
    "def strict_l0norm(A):\n",
    "    return np.where(A == 0, 0, 1).sum()\n",
    "\n",
    "def smoothedl0norm(A, sigma):\n",
    "    N = functools.reduce(operator.mul, A.shape)\n",
    "    # exp = np.sum( np.exp(-(A*A)/(2*sigma*sigma)) )\n",
    "    # print(exp)\n",
    "    # l0_norm = N - exp\n",
    "    EPS = 0.0000001\n",
    "    A_ = A.flatten()\n",
    "    l0_norm = 0\n",
    "    for a in A_:\n",
    "        if a > EPS:\n",
    "            l0_norm += 1\n",
    "    return l0_norm\n",
    "\n",
    "def getimages():\n",
    "    exim = util.ExampleImages(scaled=True, zoom=0.5, gray=True)\n",
    "    S1 = exim.image('barbara.png', idxexp=np.s_[10:522, 100:612])\n",
    "    S2 = exim.image('kodim23.png', idxexp=np.s_[:, 60:572])\n",
    "    S3 = exim.image('monarch.png', idxexp=np.s_[:, 160:672])\n",
    "    S4 = exim.image('sail.png', idxexp=np.s_[:, 210:722])\n",
    "    S5 = exim.image('tulips.png', idxexp=np.s_[:, 30:542])\n",
    "    return np.dstack((S1, S2, S3, S4, S5))\n",
    "\n",
    "def saveimg(img, filename, title=None):\n",
    "    fig = plot.figure(figsize=(7, 7))\n",
    "    plot.imview(img, fig=fig)\n",
    "    fig.savefig(filename)\n",
    "    plot.close()\n",
    "    mplot.close()\n",
    "\n",
    "# imgs.shape == (R, C, imgR, imgC) or (C, imgR, imgC)\n",
    "def saveimg2D(imgs, filename, titles=None):\n",
    "    if imgs.ndim == 3:\n",
    "        imgs = np.array([imgs])\n",
    "    if titles is not None and titles.ndim == 3:\n",
    "        titles = np.array([titles])\n",
    "    R = imgs.shape[0]\n",
    "    C = imgs.shape[1]\n",
    "    fig = plot.figure(figsize=(7*C, 7*R))\n",
    "    for r in range(R):\n",
    "        for c in range(C):\n",
    "            ax = fig.add_subplot(R, C, r*C + c + 1)\n",
    "            s = None\n",
    "            if titles is not None:\n",
    "                s = titles[r][c]\n",
    "            plot.imview(imgs[r][c], title=s, fig=fig, ax=ax)\n",
    "    plot.savefig(filename)\n",
    "    plot.close()\n",
    "    mplot.close()\n",
    "\n",
    "# be careful of non-robust implementation\n",
    "def format_sig(signal):\n",
    "    return np.transpose(signal, (3, 0, 1, 2, 4)).squeeze()\n",
    "\n",
    "def saveXimg(cri, Xr, filename):\n",
    "    # print(Xr.shape)\n",
    "    X = np.sum(abs(Xr), axis=cri.axisM).squeeze()\n",
    "    fig = plot.figure(figsize=(7, 7))\n",
    "    plot.imview(X, cmap=plot.cm.Blues, fig=fig)\n",
    "    fig.savefig(filename)\n",
    "    plot.close()\n",
    "    mplot.close()\n",
    "\n",
    "def saveXhist(Xr, filename):\n",
    "    Xr_ = abs(Xr.flatten())\n",
    "    fig = plot.figure(figsize=(7*10, 7))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.hist(Xr_, bins=500, density=True)\n",
    "    fig.savefig(filename)\n",
    "    plot.close()\n",
    "    mplot.close()\n",
    "\n",
    "def save_result(D0, D, X, S, S_reconstructed, filename):\n",
    "    titles = [[], []]\n",
    "    r1 = []\n",
    "    for k in range(S.shape[-1]):\n",
    "        r1.append(S.T[k].T)\n",
    "        titles[0].append('')\n",
    "    r1.append(util.tiledict(D0))\n",
    "    titles[0].append('')\n",
    "    r2 = []\n",
    "    for k in range(S.shape[-1]):\n",
    "        r2.append(S_reconstructed.T[k].T)\n",
    "        psnr = sm.psnr(S.T[k].T, S_reconstructed.T[k].T)\n",
    "        ssim = compare_ssim(S.T[k].T, S_reconstructed.T[k].T)\n",
    "        l0 = strict_l0norm(np.rollaxis(X, 2)[k])\n",
    "        titles[1].append(\"PSNR: %.3fdb\\nSSIM: %.4f\\nl0norm: %d\" % (psnr, ssim, l0))\n",
    "    r2.append(util.tiledict(D))\n",
    "    titles[1].append('')\n",
    "    saveimg2D(np.array([r1, r2]), filename, np.array(titles))\n",
    "\n",
    "def compressedXk(Xrk, size_rate):\n",
    "    Xrk = Xrk.copy()\n",
    "    X_flat = np.ravel(Xrk)\n",
    "    n = math.ceil(X_flat.size*(1 - size_rate))\n",
    "    print(str(X_flat.size) + \" -> \" + str(X_flat.size - n))\n",
    "    for i in np.argsort(abs(X_flat))[0:n]:\n",
    "        X_flat[i] = 0\n",
    "    return Xrk\n",
    "\n",
    "def to_inative(X, sigma):\n",
    "    return np.where(X < sigma, 0, X)\n",
    "\n",
    "# a specific axis to 1-length\n",
    "# copied\n",
    "def compress_axis(A, axis, i):\n",
    "    idx = [slice(None)]*A.ndim\n",
    "    idx[axis] = slice(i, i + 1)\n",
    "    return A[tuple(idx)]\n",
    "\n",
    "def compress_axis_op(A, axis, i):\n",
    "    idx = [slice(None)]*A.ndim\n",
    "    idx[axis] = slice(i, i + 1)\n",
    "    return tuple(idx)\n",
    "\n",
    "def reconstruct(cri, Dr, Xr):\n",
    "    Xf = sl.rfftn(Xr, s=cri.Nv, axes=cri.axisN)\n",
    "    Df = sl.rfftn(Dr, s=cri.Nv, axes=cri.axisN)\n",
    "    return sl.irfftn(sl.inner(Df, Xf, axis=cri.axisM), s=cri.Nv, axes=cri.axisN)\n",
    "\n",
    "def save_reconstructed(cri, Dr, Xr, Sr, filename, Sr_add=None):\n",
    "    Sr_ = reconstruct(cri, Dr, Xr)\n",
    "    if Sr_add is None:\n",
    "        Sr_add = np.zeros_like(Sr)\n",
    "    img = np.stack((format_sig(Sr + Sr_add), format_sig(Sr_ + Sr_add)), axis=1)\n",
    "    saveimg2D(img, filename)\n",
    "\n",
    "def compressedX(cri, Xr, Sr, size_rate):\n",
    "    Xr_cmp = Xr.copy()\n",
    "    for k in range(cri.K):\n",
    "        s = compress_axis_op(Xr_cmp, cri.axisK, k)\n",
    "        Xr_cmp[s] = compressedXk(Xr_cmp[s], (Sr.size / Xr.size)*size_rate)\n",
    "    return Xr_cmp\n",
    "\n",
    "def calcXr(cri, Dr, Sr, lmbda=5e-2):\n",
    "    opt = cbpdn.ConvBPDN.Options({'Verbose': True, 'MaxMainIter': 200,\n",
    "                                  'RelStopTol': 5e-3, 'AuxVarObj': False})\n",
    "    b = cbpdn.ConvBPDN(Dr.squeeze(), Sr.squeeze(), lmbda, opt, dimK=cri.dimK, dimN=cri.dimN)\n",
    "    Xr = b.solve()\n",
    "    return Xr\n",
    "\n",
    "def evaluate_result(cri, Dr0, Dr, Sr, Sr_add=None, lmbda=5e-2, title='result.png'):\n",
    "    Xr_ = calcXr(cri, Dr, Sr, lmbda)\n",
    "    print(\"strict l0 norm\", strict_l0norm(Xr_))\n",
    "    print(\"l2norm: \", l2norm(Xr_))\n",
    "    for k in range(cri.K):\n",
    "        print(\"image %d: strict l0 norm %f\" % (k, strict_l0norm(compress_axis(Xr_, cri.axisK, k))))\n",
    "    if Sr_add is None:\n",
    "        Sr_add = np.zeros_like(Sr)\n",
    "    save_result(Dr0.squeeze(), Dr.squeeze(), Xr_.squeeze(), (Sr + Sr_add).squeeze(), (reconstruct(cri, Dr, Xr_) + Sr_add).squeeze(), title)\n",
    "\n",
    "def l2norm_minimize(cri, Dr, Sr):\n",
    "    Df = sl.rfftn(Dr, s=cri.Nv, axes=cri.axisN) # implicitly zero-padding\n",
    "    Sf = sl.rfftn(Sr, s=cri.Nv, axes=cri.axisN) # implicitly zero-padding\n",
    "    Xf = np.conj(Df) / sl.inner(Df, np.conj(Df), axis=cri.axisM) * Sf\n",
    "    Xr = sl.irfftn(Xf, s=cri.Nv, axes=cri.axisN)\n",
    "\n",
    "    Sr_ = sl.irfftn(sl.inner(Df, Xf, axis=cri.axisM), s=cri.Nv, axes=cri.axisN)\n",
    "    # print(l2norm(np.random.randn(*Xr.shape)))\n",
    "    # print(l2norm(Xr))\n",
    "    # print(l2norm(Sr - Sr_))\n",
    "    po = np.stack((format_sig(Sr), format_sig(Sr_)), axis=1)\n",
    "    saveimg2D(po, 'l2norm_minimization_test.png') # the right side is Sr_\n",
    "    return Xr\n",
    "\n",
    "def convert_to_Df(D):\n",
    "    Dr = np.asarray(D.reshape(cri.shpD), dtype=S.dtype)\n",
    "    Df = sl.rfftn(Dr, cri.Nv, cri.axisN)\n",
    "    return Df\n",
    "\n",
    "def convert_to_Sf(S):\n",
    "    Sr = np.asarray(S.reshape(cri.shpS), dtype=S.dtype)\n",
    "    Sf = sl.rfftn(Sr, None, cri.axisN)\n",
    "    return Sf\n",
    "\n",
    "def convert_to_S(Sf):\n",
    "    S = sl.irfftn(Sf, cri.Nv, cri.axisN).squeeze()\n",
    "    return S\n",
    "\n",
    "def convert_to_Xf(X):\n",
    "    Xr = np.asarray(X.reshape(cri.shpX), dtype=S.dtype)\n",
    "    Xf = sl.rfftn(Xr, cri.Nv, cri.axisN)\n",
    "    return Xf\n",
    "\n",
    "def convert_to_X(Xf):\n",
    "    X = sl.irfftn(Xf, cri.Nv, cri.axisN).squeeze()\n",
    "    return X\n",
    "\n",
    "\n",
    "def derivD_spdomain(cri, Xr, Sr, Df, Xf, dict_Nv):\n",
    "    B = sl.irfftn(sl.inner(Df, Xf, axis=cri.axisM), s=cri.Nv, axes=cri.axisN) - Sr\n",
    "    B = B[np.newaxis, np.newaxis,]\n",
    "    Xshifted = np.ones(dict_Nv + Xr.shape) * Xr\n",
    "    \n",
    "    N1 = 0\n",
    "    N2 = 1\n",
    "    I = 2\n",
    "    J = 3\n",
    "\n",
    "    print(\"start shifting\")\n",
    "    for n1 in range(dict_Nv[0]):\n",
    "        for n2 in range(dict_Nv[1]):\n",
    "            Xshifted[n1][n2] = np.roll(Xshifted[n1][n2], (n1, n2), axis=(I, J))\n",
    "            # print(\"shifted \", (n1, n2))\n",
    "    ret = np.sum(np.conj(B) * Xshifted, axis=(I, J, 2 + cri.axisK), keepdims=True)\n",
    "    print(ret.shape)\n",
    "    ret = ret[:, :, 0, 0]\n",
    "    print(ret.shape)\n",
    "    return ret\n",
    "\n",
    "def goldenRatioSearch(function, rng, cnt):\n",
    "    # 黄金探索法によるステップ幅の最適化\n",
    "    gamma = (-1+np.sqrt(5))/2\n",
    "    a = rng[0]\n",
    "    b = rng[1]\n",
    "    p = b-gamma*(b-a)\n",
    "    q = a+gamma*(b-a)\n",
    "    Fp = function(p)\n",
    "    Fq = function(q)\n",
    "    width = 1e8\n",
    "    for i in range(cnt):\n",
    "        if Fp <= Fq:\n",
    "            b = q\n",
    "            q = p\n",
    "            Fq = Fp\n",
    "            p = b-gamma*(b-a)\n",
    "            Fp = function(p)\n",
    "        else:\n",
    "            a = p\n",
    "            p = q\n",
    "            Fp = Fq\n",
    "            q = a+gamma*(b-a)\n",
    "            Fq = function(q)\n",
    "            width = abs(b-a)/2\n",
    "    alpha = (a+b)/2\n",
    "    return alpha\n",
    "\n",
    "# 下に凸\n",
    "def ternary_search(f, rng, cnt):\n",
    "    left = rng[0]\n",
    "    right = rng[1]\n",
    "    for i in range(cnt):\n",
    "        if f((left * 2 + right) / 3) > f((left + right * 2) / 3):\n",
    "            left = (left * 2 + right) / 3\n",
    "        else:\n",
    "            right = (left + right * 2) / 3\n",
    "    return (left + right) / 2\n",
    "\n",
    "def min_max(x, axis=None):\n",
    "    min = x.min(axis=axis, keepdims=True)\n",
    "    max = x.max(axis=axis, keepdims=True)\n",
    "    return (x - min) / (max - min)\n",
    "\n",
    "def zscore(x, axis = None):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore\n",
    "\n",
    "def normalize(v, axis=-1, order=2):\n",
    "    l2 = np.linalg.norm(v, ord=order, axis=axis, keepdims=True)\n",
    "    l2[l2==0] = 1\n",
    "    return v/l2\n",
    "\n",
    "def to_frequency(cri, Ar):\n",
    "    return sl.rfftn(Ar, s=cri.Nv, axes=cri.axisN)\n",
    "\n",
    "def to_spatial(cri, Af):\n",
    "    return sl.irfftn(Af, s=cri.Nv, axes=cri.axisN)\n",
    "\n",
    "def update_dict(cri, Pcn, crop_op, Xr, Gr, Hr, Sf, param_rho):\n",
    "    # D step\n",
    "    Xf = to_frequency(cri, Xr)\n",
    "    Gf = to_frequency(cri, Gr)\n",
    "    Hf = to_frequency(cri, Hr)\n",
    "    XSf = sl.inner(np.conj(Xf), Sf, cri.axisK)\n",
    "    b = XSf + param_rho * (Gf - Hf)\n",
    "    Df = sl.solvemdbi_ism(Xf, param_rho, b, cri.axisM, cri.axisK)\n",
    "    Dr = to_spatial(cri, Df)\n",
    "    # G step\n",
    "    Gr = Pcn(Dr + Hr)\n",
    "    # H step\n",
    "    Hr = Hr + Dr - Gr\n",
    "    return Gr[crop_op], Hr\n",
    "\n",
    "def nakashizuka_solve(\n",
    "    cri, Dr0, Xr, Sr,\n",
    "    final_sigma,\n",
    "    maxitr = 40,\n",
    "    param_mu = 1,\n",
    "    param_lambda = 1e-2,\n",
    "    debug_dir = None\n",
    "):\n",
    "    \n",
    "    param_rho = 0.5\n",
    "\n",
    "    Xr = Xr.copy()\n",
    "    Sr = Sr.copy()\n",
    "    Dr = Dr0.copy()\n",
    "    Hr = np.zeros_like(cnvrep.zpad(Dr, cri.Nv))\n",
    "\n",
    "    Sf = to_frequency(cri, Sr)\n",
    "\n",
    "    # sigma set\n",
    "    first_sigma = Xr.max() * 4 # 初期係数の要素の最大値の4倍\n",
    "    # σ←cσ(c < 1)のcの決定\n",
    "    c = (final_sigma / first_sigma) ** (1/(maxitr - 1))\n",
    "    print(\"c = %.8f\" % c)\n",
    "    sigma_list = []\n",
    "    sigma_list.append(first_sigma)\n",
    "    for i in range(maxitr - 1):\n",
    "        sigma_list.append(sigma_list[i]*c)\n",
    "    \n",
    "    crop_op = []\n",
    "    for l in Dr.shape:\n",
    "        crop_op.append(slice(0, l))\n",
    "    crop_op = tuple(crop_op)\n",
    "    Pcn = cnvrep.getPcn(Dr.shape, cri.Nv, cri.dimN, cri.dimCd, zm=False)\n",
    "\n",
    "    updcnt = 0\n",
    "    dictcnt = 0\n",
    "    for sigma in sigma_list:\n",
    "        print(\"sigma = %.8f\" % sigma)\n",
    "        # Xf_old = sl.rfftn(Xr, cri.Nv, cri.axisN)\n",
    "        for l in range(1):\n",
    "            # print(\"l0norm: %f\" % l0norm(Xr, sigma_list[-1]))\n",
    "            # print('error1: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "            # print(\"l2(Xr): %.6f, l2(delta): %.6f\" % (l2norm(Xr), l2norm(delta)))\n",
    "\n",
    "            # 係数の勾配降下\n",
    "            delta = Xr * np.exp(-(Xr*Xr) / (2*sigma*sigma))\n",
    "            Xr = Xr - param_mu*delta# + np.random.randn(*Xr.shape)*sigma*1e-1\n",
    "            Xf = to_frequency(cri, Xr)\n",
    "\n",
    "            # print('error2: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "\n",
    "            # 係数の射影\n",
    "            Df = to_frequency(cri, Dr)\n",
    "            b = Xf / param_lambda + np.conj(Df) * Sf\n",
    "            Xf = sl.solvedbi_sm(Df, 1/param_lambda, b, axis=cri.axisM)\n",
    "            Xr = to_spatial(cri, Xf).astype(np.float32)\n",
    "            \n",
    "            # print('error3: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "\n",
    "            # save_reconstructed(cri, Dr, Xr, Sr, \"./rec/%da.png\" % reccnt)\n",
    "            # saveXhist(Xr, \"./hist/%da.png\" % reccnt)\n",
    "\n",
    "            # ADMMによる辞書更新\n",
    "            Dr, Hr = update_dict(cri, Pcn, crop_op, Xr, Dr, Hr, Sf, param_rho)\n",
    "            Df = to_frequency(cri, Dr)\n",
    "            \n",
    "            # print('error4: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "\n",
    "            # # project X to solution space\n",
    "            # b = sl.inner(Df, Xf, axis=cri.axisM) - Sf\n",
    "            # c = sl.inner(Df, np.conj(Df), axis=cri.axisM)\n",
    "            # Xf = Xf - np.conj(Df) / c * b\n",
    "            # Xr = sl.irfftn(Xf, s=cri.Nv, axes=cri.axisN)\n",
    "\n",
    "            # print('error5: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "            \n",
    "            if debug_dir is not None:\n",
    "                saveimg(util.tiledict(Dr.squeeze()), debug_dir + \"/dict/%d.png\" % updcnt)\n",
    "\n",
    "            updcnt += 1\n",
    "\n",
    "        # saveXhist(Xr, \"Xhist_sigma=\" + str(sigma) + \".png\")\n",
    "    \n",
    "    # print(\"l0 norm of final X: %d\" % smoothedl0norm(Xr, 0.00001))\n",
    "    plot.close()\n",
    "    mplot.close()\n",
    "    return Dr\n",
    "\n",
    "def mysolve(\n",
    "    cri, Dr0, Xr, Sr,\n",
    "    final_sigma,\n",
    "    maxitr = 40,\n",
    "    param_mu = 1,\n",
    "    debug_dir = None\n",
    "):\n",
    "    Dr = Dr0.copy()\n",
    "    Xr = Xr.copy()\n",
    "    Sr = Sr.copy()\n",
    "\n",
    "    #離散フーリエ変換\n",
    "    Df = sl.rfftn(Dr, s=cri.Nv, axes=cri.axisN)\n",
    "    Sf = sl.rfftn(Sr, s=cri.Nv, axes=cri.axisN)\n",
    "    Xf = sl.rfftn(Xr, s=cri.Nv, axes=cri.axisN)\n",
    "    alpha = 1e0\n",
    "\n",
    "    # sigma set\n",
    "    first_sigma = Xr.max()*4    # 初期係数の要素の最大値の4倍\n",
    "    # σ←cσ(c < 1)のcの決定\n",
    "    c = (final_sigma / first_sigma) ** (1/(maxitr - 1))\n",
    "    print(\"c = %.8f\" % c)\n",
    "    sigma_list = []\n",
    "    sigma_list.append(first_sigma)\n",
    "    for i in range(maxitr - 1):\n",
    "        sigma_list.append(sigma_list[i]*c)\n",
    "        print(sigma_list[-1])\n",
    "    \n",
    "    # 辞書のクロップする領域を指定\n",
    "    crop_op = []\n",
    "    for l in Dr.shape:\n",
    "        crop_op.append(slice(0, l))\n",
    "    crop_op = tuple(crop_op)\n",
    "    print(crop_op)\n",
    "    \n",
    "    # 射影関数のインスタンス化\n",
    "    Pcn = cnvrep.getPcn(Dr.shape, cri.Nv, cri.dimN, cri.dimCd, zm=False)\n",
    "\n",
    "    updcnt = 0\n",
    "    for sigma in sigma_list:\n",
    "        print(\"sigma = %.8f\" % sigma)\n",
    "        # print(\"l0norm: %f\" % l0norm(Xr, sigma_list[-1]))\n",
    "        # print('error1: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "        \n",
    "        # 係数の勾配降下\n",
    "        delta = Xr * np.exp(-(Xr*Xr) / (2*sigma*sigma))\n",
    "        # print(\"l2(Xr): %.6f, l2(delta): %.6f\" % (l2norm(Xr), l2norm(delta)))\n",
    "        Xr = Xr - param_mu*delta# + np.random.randn(*Xr.shape)*sigma*1e-1\n",
    "        Xf = sl.rfftn(Xr, cri.Nv, cri.axisN)\n",
    "        # saveXhist(Xr, \"./hist/%db.png\" % reccnt)\n",
    "\n",
    "        # print('error2: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "        # if debug_dir is not None:\n",
    "        #     save_reconstructed(cri, Dr, Xr, Sr, debug_dir + '/%drecA.png' % updcnt)\n",
    "        # DXf = sl.inner(Df, Xf, axis=cri.axisM)\n",
    "        # gamma = (np.sum(np.conj(DXf) * Sf, axis=cri.axisN, keepdims=True) + np.sum(DXf * np.conj(Sf), axis=cri.axisN, keepdims=True)) / 2 / np.sum(np.conj(DXf) * DXf, axis=cri.axisN, keepdims=True)\n",
    "        # print(gamma)\n",
    "        # print(gamma.shape, ' * ', Xr.shape)\n",
    "        # gamma = np.real(gamma)\n",
    "        # Xr = Xr * gamma\n",
    "        # Xf = to_frequency(cri, Xr)\n",
    "\n",
    "        # if debug_dir is not None:\n",
    "        #     save_reconstructed(cri, Dr, Xr, Sr, debug_dir + '/%drecB.png' % updcnt)\n",
    "        \n",
    "        # print('error3: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "        # print(\"max: \", np.max(Xr))\n",
    "\n",
    "        # 辞書の勾配降下\n",
    "        B = sl.inner(Xf, Df, axis=cri.axisM) - Sf\n",
    "        derivDf = sl.inner(np.conj(Xf), B, axis=cri.axisK)\n",
    "        # derivDr = sl.irfftn(derivDf, s=cri.Nv, axes=cri.axisN)[crop_op]\n",
    "        def func(alpha):\n",
    "            Df_ = Df - alpha * derivDf\n",
    "            Dr_ = sl.irfftn(Df_, s=cri.Nv, axes=cri.axisN)[crop_op]\n",
    "            Df_ = sl.rfftn(Dr_, s=cri.Nv, axes=cri.axisN)\n",
    "            Sf_ = sl.inner(Df_, Xf, axis=cri.axisM)\n",
    "            return l2norm(Sr - sl.irfftn(Sf_, s=cri.Nv, axes=cri.axisN))\n",
    "        choice = np.array([func(alpha / 2), func(alpha), func(alpha * 2)]).argmin()\n",
    "        alpha *= [0.5, 1, 2][choice]\n",
    "        print(\"alpha: \", alpha)\n",
    "        Df = Df - alpha * derivDf\n",
    "        Dr = Pcn(sl.irfftn(Df, s=cri.Nv, axes=cri.axisN))[crop_op]\n",
    "        print(l2norm(Dr.T[0]))\n",
    "        Df = sl.rfftn(Dr, s=cri.Nv, axes=cri.axisN)\n",
    "\n",
    "        if debug_dir is not None:\n",
    "            saveimg(util.tiledict(Dr.squeeze()), debug_dir + \"/dict/%d.png\" % updcnt)\n",
    "        # if debug_dir is not None:\n",
    "        #     save_reconstructed(cri, Dr, Xr, Sr, debug_dir + '/%drecC.png' % updcnt)\n",
    "        # dictcnt += 1\n",
    "\n",
    "        # print('error4: ', l2norm(Sr - reconstruct(cri, Dr, Xr)))\n",
    "\n",
    "        # save_reconstructed(cri, Dr, Xr, Sr, debug_dir + \"/rec/%dc.png\" % updcnt)\n",
    "\n",
    "        # 辞書の射影\n",
    "        b = sl.inner(Df, Xf, axis=cri.axisM) - Sf\n",
    "        c = sl.inner(Df, np.conj(Df), axis=cri.axisM)\n",
    "        Xf = Xf - np.conj(Df) / c * b\n",
    "        Xr = sl.irfftn(Xf, s=cri.Nv, axes=cri.axisN)\n",
    "        \n",
    "        # save_reconstructed(cri, Dr, Xr, Sr, debug_dir + \"rec/%dd.png\" % updcnt)\n",
    "        # saveXhist(Xr, debug_dir + \"hist/%db.png\" % updcnt)\n",
    "        updcnt += 1\n",
    "    \n",
    "    # print(\"l0 norm of final X: %d\" % smoothedl0norm(Xr, 0.00001))\n",
    "    plot.close()\n",
    "    mplot.close()\n",
    "    return Dr\n",
    "\n",
    "def sporcosolve(cri, Dr0, Sr, maxitr=200):\n",
    "    Dr0 = Dr0.copy()\n",
    "    Sr = Sr.copy()\n",
    "    lmbda = 0.2\n",
    "    opt = cbpdndl.ConvBPDNDictLearn.Options({'Verbose': True, 'MaxMainIter': maxitr,\n",
    "                            'CBPDN': {'rho': 50.0*lmbda + 0.5},\n",
    "                            'CCMOD': {'rho': 10.0, 'ZeroMean': True}},\n",
    "                            dmethod='cns')\n",
    "    # ADMMによる係数、辞書の最適化\n",
    "    d = cbpdndl.ConvBPDNDictLearn(Dr0.squeeze(), Sr.squeeze(), lmbda, opt, dmethod='cns')\n",
    "    Dr = d.solve()\n",
    "    print(\"ConvBPDNDictLearn solve time: %.2fs\" % d.timer.elapsed('solve'))\n",
    "    return Dr\n",
    "\n",
    "def testdict(cri, Dr0, Dr, Slr, Shr, dir,\n",
    "    lambdas = [\n",
    "        '1e-2',\n",
    "        '2e-2',\n",
    "        '5e-2',\n",
    "        '1e-1',\n",
    "        '2e-1',\n",
    "        '5e-1',\n",
    "    ]):\n",
    "    S = (Slr + Shr).squeeze()\n",
    "    ret = [[] for k in range(cri.K)]\n",
    "    for s in lambdas:\n",
    "        print('==========================================')\n",
    "        print('test dictionary (lambda = %s)' % s)\n",
    "        print('==========================================')\n",
    "        lmbda = float(s)\n",
    "        # ADMMによる係数最適化\n",
    "        Xr = calcXr(cri, Dr, Shr, lmbda=lmbda)\n",
    "        X = Xr.squeeze()\n",
    "        S_ = (reconstruct(cri, Dr, Xr) + Slr).squeeze()\n",
    "        for k in range(cri.K):\n",
    "            d = {\n",
    "                'lambda': lmbda,\n",
    "                'psnr': sm.psnr(S.T[k].T, S_.T[k].T),\n",
    "                'ssim': compare_ssim(S.T[k].T, S_.T[k].T),\n",
    "                'l0norm': strict_l0norm(np.rollaxis(X, 2)[k]),\n",
    "            }\n",
    "            pprint.pprint(d) # 標準出力を整える\n",
    "            ret[k].append(d) # 画像ごとの係数評価を格納\n",
    "\n",
    "        save_result(Dr0.squeeze(), Dr.squeeze(), X, (Slr + Shr).squeeze(), S_, dir + '/result_lambda=%s.png' % s)\n",
    "    return ret\n",
    "\n",
    "def test_mysolve(cri_train, Dr0, Shr_train, cri_test, Slr_test, Shr_test, outdir='.'):\n",
    "    # 反復回数を変えて学習\n",
    "    itrs = [5, 10, 20, 30, 40, 50]\n",
    "    data = [[] for k in range(cri_test.K)]\n",
    "    times = []\n",
    "\n",
    "    # dummy (for memory allocate on google colab)\n",
    "    Xr = l2norm_minimize(cri_train, Dr0, Shr_train)\n",
    "    Dr = mysolve(cri_train, Dr0, Xr, Shr_train, 1e-4, maxitr=2)\n",
    "\n",
    "    for maxitr in itrs:\n",
    "        # 実行時間計測\n",
    "        start = time.time()\n",
    "        # 辞書学習\n",
    "        # 初期係数の決定\n",
    "        Xr = l2norm_minimize(cri_train, Dr0, Shr_train) #信号とのL2誤差を最小にする係数を返す\n",
    "        Dr = mysolve(cri_train, Dr0, Xr, Shr_train, 1e-4, maxitr=maxitr) #更新式\n",
    "        end = time.time()\n",
    "        times.append({'maxitr': maxitr, 'time': end - start})\n",
    "\n",
    "        dir = outdir + '/mysolve_itr=%d' % maxitr\n",
    "        if os.path.isdir(dir):\n",
    "            shutil.rmtree(dir)\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "        # 学習した辞書の評価\n",
    "        res = testdict(cri_test, Dr0, Dr, Slr_test, Shr_test, dir,\n",
    "            lambdas = [\n",
    "                '1e-3',\n",
    "                '3e-3',\n",
    "                '1e-2',\n",
    "                '3e-2',\n",
    "                '1e-1',\n",
    "                '3e-1',])\n",
    "        for k in range(cri_test.K):\n",
    "            for d in res[k]:\n",
    "                d['maxitr'] = maxitr\n",
    "            data[k] += res[k]\n",
    "    return data, times\n",
    "\n",
    "def test_nakashizuka_solve(cri_train, Dr0, Shr_train, cri_test, Slr_test, Shr_test, outdir='.'):\n",
    "    itrs = [20, 40, 60, 100, 200, 300]\n",
    "    data = [[] for k in range(cri_test.K)]\n",
    "    times = []\n",
    "    \n",
    "    # dummy (for memory allocate on google colab)\n",
    "    Xr = l2norm_minimize(cri_train, Dr0, Shr_train)\n",
    "    Dr = nakashizuka_solve(cri_train, Dr0, Xr, Shr_train, 1e-4, maxitr=2)\n",
    "\n",
    "    for maxitr in itrs:\n",
    "        start = time.time()\n",
    "        Xr = l2norm_minimize(cri_train, Dr0, Shr_train) #L2誤差を最小にする係数を返す\n",
    "        Dr = nakashizuka_solve(cri_train, Dr0, Xr, Shr_train, 1e-4, maxitr=maxitr)\n",
    "        end = time.time()\n",
    "        times.append({'maxitr': maxitr, 'time': end - start})\n",
    "\n",
    "        dir = outdir + '/nakashizuka_solve_itr=%d' % maxitr\n",
    "        if os.path.isdir(dir):\n",
    "            shutil.rmtree(dir)\n",
    "        os.makedirs(dir)\n",
    "        res = testdict(cri_test, Dr0, Dr, Slr_test, Shr_test, dir)\n",
    "        for k in range(cri_test.K):\n",
    "            for d in res[k]:\n",
    "                d['maxitr'] = maxitr\n",
    "            data[k] += res[k]\n",
    "    return data, times\n",
    "\n",
    "def test_sporcosolve(cri_train, Dr0, Shr_train, cri_test, Slr_test, Shr_test, outdir='.'):\n",
    "    itrs = [20, 40, 80, 120, 160, 200]\n",
    "    # itrs = [200]\n",
    "    data = [[] for k in range(cri_test.K)]\n",
    "    times = []\n",
    "\n",
    "    # dummy (for memory allocate on google colab)\n",
    "    Dr = sporcosolve(cri_train, Dr0, Shr_train, maxitr=2)\n",
    "\n",
    "    for maxitr in itrs:\n",
    "        start = time.time()\n",
    "        Dr = sporcosolve(cri_train, Dr0, Shr_train, maxitr=maxitr)\n",
    "        end = time.time()\n",
    "        times.append({'maxitr': maxitr, 'time': end - start})\n",
    "\n",
    "        dir = outdir + '/sporcosolve_itr=%d' % maxitr\n",
    "        if os.path.isdir(dir):\n",
    "            shutil.rmtree(dir)\n",
    "        os.makedirs(dir)\n",
    "        res = testdict(cri_test, Dr0, Dr, Slr_test, Shr_test, dir)\n",
    "        for k in range(cri_test.K):\n",
    "            for d in res[k]:\n",
    "                d['maxitr'] = maxitr\n",
    "            data[k] += res[k]\n",
    "    return data, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5 images, each is 256x256.\n"
    }
   ],
   "source": [
    "# 学習用画像をダウン平均地平均値\n",
    "S = getimages().astype(np.float32)\n",
    "print(\"%d images, each is %dx%d.\" % (S.shape[2], S.shape[0], S.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画素値の平均を0にする\n",
    "Sl = np.zeros_like(S)\n",
    "Smean = np.mean(S*2, axis=(0, 1))\n",
    "Sh = S*2 - Smean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cri_test\n{'C': 1,\n 'Cd': 1,\n 'K': 5,\n 'M': 256,\n 'N': 65536,\n 'Nv': (256, 256),\n 'axisC': 2,\n 'axisK': 3,\n 'axisM': 4,\n 'axisN': (0, 1),\n 'dimC': 0,\n 'dimCd': 0,\n 'dimK': 1,\n 'dimN': 2,\n 'shpD': (12, 12, 1, 1, 256),\n 'shpS': (256, 256, 1, 5, 1),\n 'shpX': (256, 256, 1, 5, 256)}\n(12, 12, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n"
    }
   ],
   "source": [
    "#TODO: explicitly zero-padding (for me, foolish)\n",
    "D = np.random.randn(12, 12, 256)\n",
    "\n",
    "#畳み込み型辞書学習に必要な変数の次元を参照\n",
    "cri = cnvrep.CSC_ConvRepIndexing(D, S)\n",
    "# shpS(N0,  N1, ...,  C,   K,   1) C is the number of channels in S\n",
    "# shpD(N0,  N1, ...,  1,   1,   M) K is the number of signals in S\n",
    "# shpX(N0,  N1, ...,  C,   K,   M) M is the number of filters in D\n",
    "print(\"cri_test\"+\"\\n\"+str(cri))\n",
    "Dr0 = np.asarray(D.reshape(cri.shpD), dtype=S.dtype)\n",
    "Slr = np.asarray(Sl.reshape(cri.shpS), dtype=S.dtype)\n",
    "Shr = np.asarray(Sh.reshape(cri.shpS), dtype=S.dtype)\n",
    "#Shf = sl.rfftn(Shr, s=cri.Nv, axes=cri.axisN) # implicitly zero-padding\n",
    "\n",
    "crop_op = []\n",
    "for l in Dr0.shape:\n",
    "    crop_op.append(slice(0, l))\n",
    "crop_op = tuple(crop_op)\n",
    "print(Dr0.shape)\n",
    "\n",
    "# 辞書のゼロパディングと正規化\n",
    "Dr0 = cnvrep.getPcn(Dr0.shape, cri.Nv, cri.dimN, cri.dimCd, zm=False)(cnvrep.zpad(Dr0, cri.Nv)) # normalise(zpad(bcrop(x, dsz, dimN), Nv), dimN + dimC)を返す\n",
    "print(Dr0.shape)\n",
    "Dr0 = Dr0[crop_op]\n",
    "print(Dr0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cri_test\n{'C': 1,\n 'Cd': 1,\n 'K': 2,\n 'M': 256,\n 'N': 65536,\n 'Nv': (256, 256),\n 'axisC': 2,\n 'axisK': 3,\n 'axisM': 4,\n 'axisN': (0, 1),\n 'dimC': 0,\n 'dimCd': 0,\n 'dimK': 1,\n 'dimN': 2,\n 'shpD': (12, 12, 1, 1, 256),\n 'shpS': (256, 256, 1, 2, 1),\n 'shpX': (256, 256, 1, 2, 256)}\n"
    }
   ],
   "source": [
    "#テスト用画像をダウンロード\n",
    "\n",
    "# scales=Trueのとき、画素値を正規化\n",
    "# zoom:画像のスケールを調整\n",
    "exim1 = util.ExampleImages(scaled=True, zoom=0.5, pth='./')\n",
    "S1_test = exim1.image('couple.tiff') #(256, 256)\n",
    "#print(S1_test.shape)\n",
    "exim2 = util.ExampleImages(scaled=True, zoom=1, pth='./')\n",
    "S2_test = exim2.image('LENNA.bmp') #(256, 256)\n",
    "#画像2枚を1つにまとめる\n",
    "S_test = np.dstack((S1_test, S2_test)) #(x,y,枚数)\n",
    "\n",
    "#畳み込み型辞書学習に必要な変数の次元を参照\n",
    "cri_test = cnvrep.CSC_ConvRepIndexing(D, S_test)\n",
    "# shpS(N0,  N1, ...,  C,   K,   1) C is the number of channels in S\n",
    "# shpD(N0,  N1, ...,  1,   1,   M) K is the number of signals in S\n",
    "# shpX(N0,  N1, ...,  C,   K,   M) M is the number of filters in D\n",
    "print(\"cri_test\"+\"\\n\"+str(cri_test))\n",
    "\n",
    "# Tikhonov正則化で画像を平滑化\n",
    "Sl_test, Sh_test = util.tikhonov_filter(S_test, 5, 16) #ローパス、ハイパス\n",
    "Slr_test = np.asarray(Sl_test.reshape(cri_test.shpS), dtype=S_test.dtype)\n",
    "Shr_test = np.asarray(Sh_test.reshape(cri_test.shpS), dtype=S_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "c = 0.00171042\n0.0001\n(slice(0, 12, None), slice(0, 12, None), slice(0, 1, None), slice(0, 1, None), slice(0, 256, None))\nsigma = 0.05846528\nalpha:  2.0\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n0.9999997\nsigma = 0.00010000\nalpha:  1.0\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n0.9999996\nc = 0.20336466\n0.011889771913262645\n0.0024179594628274325\n0.000491727512228819\n0.00010000000000000003\n(slice(0, 12, None), slice(0, 12, None), slice(0, 1, None), slice(0, 1, None), slice(0, 256, None))\nsigma = 0.05846528\nalpha:  2.0\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n0.9999997\nsigma = 0.01188977\nalpha:  4.0\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n1.0\nsigma = 0.00241796\nalpha:  2.0\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n0.99999976\nsigma = 0.00049173\nalpha:  1.0\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n1.0\nsigma = 0.00010000\nalpha:  0.5\n(256, 129, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(256, 256, 1, 1, 256)\n(12, 12, 1, 1, 256)\n0.99999994\n==========================================\ntest dictionary (lambda = 1e-3)\n==========================================\nItn   Fnc       DFid      Regℓ1     r         s         ρ       \n----------------------------------------------------------------\n   0  2.34e+01  7.53e+00  1.58e+04  4.12e-01  2.09e+00  1.05e+00\n   1  1.82e+01  2.56e+00  1.57e+04  2.21e-01  9.63e-01  1.05e+00\n   2  1.88e+01  1.46e+00  1.73e+04  2.65e-01  5.64e-01  5.03e-01\n   3  1.96e+01  9.45e-01  1.87e+04  2.59e-01  3.99e-01  3.44e-01\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-59c894858aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_nakashizuka_solve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcri_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSlr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mysolve'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_mysolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcri_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSlr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sporcosolve'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_sporcosolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDr0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcri_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSlr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-094d19165c60>\u001b[0m in \u001b[0;36mtest_mysolve\u001b[1;34m(cri_train, Dr0, Shr_train, cri_test, Slr_test, Shr_test, outdir)\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;34m'3e-2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;34m'1e-1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                 '3e-1',])\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcri_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-094d19165c60>\u001b[0m in \u001b[0;36mtestdict\u001b[1;34m(cri, Dr0, Dr, Slr, Shr, dir, lambdas)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mlmbda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;31m# ADMMによる係数最適化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mXr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcXr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mS_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mSlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-094d19165c60>\u001b[0m in \u001b[0;36mcalcXr\u001b[1;34m(cri, Dr, Sr, lmbda)\u001b[0m\n\u001b[0;32m    147\u001b[0m                                   'RelStopTol': 5e-3, 'AuxVarObj': False})\n\u001b[0;32m    148\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbpdn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvBPDN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[0mXr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mXr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\oda-lab-h30\\lib\\site-packages\\sporco\\admm\\admm.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# X update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;31m# Implement relaxation if RelaxParam != 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\oda-lab-h30\\lib\\site-packages\\sporco\\admm\\cbpdn.py\u001b[0m in \u001b[0;36mxstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDSf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrho\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfftn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxisN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCd\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             self.Xf[:] = sl.solvedbi_sm(self.Df, self.rho, b, self.c,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\oda-lab-h30\\lib\\site-packages\\sporco\\linalg.py\u001b[0m in \u001b[0;36mrfftn\u001b[1;34m(a, s, axes)\u001b[0m\n\u001b[0;32m    240\u001b[0m     return pyfftw.interfaces.numpy_fft.rfftn(\n\u001b[0;32m    241\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         planner_effort='FFTW_MEASURE', threads=pyfftw_threads)\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\oda-lab-h30\\lib\\site-packages\\pyfftw\\interfaces\\numpy_fft.py\u001b[0m in \u001b[0;36mrfftn\u001b[1;34m(a, s, axes, norm, overwrite_input, planner_effort, threads, auto_align_input, auto_contiguous)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _Xfftn(a, s, axes, overwrite_input, planner_effort,\n\u001b[0;32m    276\u001b[0m             \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_align_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_contiguous\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             calling_func, **_norm_args(norm))\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\oda-lab-h30\\lib\\site-packages\\pyfftw\\interfaces\\_utils.py\u001b[0m in \u001b[0;36m_Xfftn\u001b[1;34m(a, s, axes, overwrite_input, planner_effort, threads, auto_align_input, auto_contiguous, calling_func, normalise_idft, ortho)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         FFTW_object(input_array=a, output_array=output_array,\n\u001b[1;32m--> 150\u001b[1;33m                 normalise_idft=normalise_idft, ortho=ortho)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outdir = './no_low-pass'\n",
    "#--------実験手法を指定-------\n",
    "# prefix = 'nakashizuka_solve' # 中静先生の論文\n",
    "prefix = 'mysolve' # 提案手法\n",
    "# prefix = 'sporcosolve' # sporcoライブラリに実装された方法（B. Wohlbergによる）\n",
    "#----------------------------------\n",
    "if prefix == 'nakashizuka_solve':\n",
    "    data, times = test_nakashizuka_solve(cri, Dr0, Shr, cri_test, Slr_test, Shr_test, outdir=outdir)\n",
    "if prefix == 'mysolve':\n",
    "    data, times = test_mysolve(cri, Dr0, Shr, cri_test, Slr_test, Shr_test, outdir=outdir)\n",
    "if prefix == 'sporcosolve':\n",
    "    data, times = test_sporcosolve(cri, Dr0, Shr, cri_test, Slr_test, Shr_test, outdir=outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}